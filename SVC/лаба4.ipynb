{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import io\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.kernel_approximation import AdditiveChi2Sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(X):\n",
    "    corr_threshold = 0.9\n",
    "    corr = X.corr()\n",
    "    drop_columns = np.full(corr.shape[0], False, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= corr_threshold:\n",
    "                drop_columns[j] = True\n",
    "    columns_dropped = X.columns[drop_columns]\n",
    "    X.drop(columns_dropped, axis=1, inplace=True)\n",
    "    return columns_dropped\n",
    "\n",
    "\n",
    "def remove_less_significant_features(X, Y):\n",
    "    sl = 0.05\n",
    "    regression_ols = None\n",
    "    columns_dropped = np.array([])\n",
    "    for itr in range(0, len(X.columns)):\n",
    "        regression_ols = sm.OLS(Y, X).fit()\n",
    "        max_col = regression_ols.pvalues.idxmax()\n",
    "        max_val = regression_ols.pvalues.max()\n",
    "        if max_val > sl:\n",
    "            X.drop(max_col, axis='columns', inplace=True)\n",
    "            columns_dropped = np.append(columns_dropped, [max_col])\n",
    "        else:\n",
    "            break\n",
    "          \n",
    "    regression_ols.summary()\n",
    "    return columns_dropped\n",
    "\n",
    "def split_normolize_data(kernel=RBFSampler(gamma=1, random_state=1)):\n",
    "    data = pd.read_csv('data.csv')\n",
    "    data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\n",
    "    print(\"applying feature engineering...\")\n",
    "    diag_map = {'M': 1.0, 'B': -1.0}\n",
    "    data['diagnosis'] = data['diagnosis'].map(diag_map)\n",
    "    Y = data['diagnosis']\n",
    "    X = data.iloc[:,1 :]\n",
    "    print(\"splitting dataset into train and test sets...\")\n",
    "    remove_correlated_features(X)\n",
    "    remove_less_significant_features(X, Y)\n",
    "    # normalize data for better convergence and to prevent overflow\n",
    "    X_normalized = MinMaxScaler().fit_transform(X.values)\n",
    "    X = pd.DataFrame(X_normalized)\n",
    "    # insert 1 in every row for intercept b\n",
    "    X.insert(loc=len(X.columns), column='intercept', value=1)\n",
    "    X = kernel.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >> FEATURE SELECTION << #\n",
    "class SVC_hand:\n",
    "    \n",
    "    def __init__(self,regularization_strength = 10000,learning_rate = 0.000001,kernel=RBFSampler(gamma=1, random_state=1)):\n",
    "        print('kernel=',kernel)\n",
    "        self.regularization_strength=regularization_strength\n",
    "        self.learning_rate=learning_rate\n",
    "        self.kernel=kernel\n",
    "    \n",
    "    def fit(self,X_train, X_test, y_train, y_test):\n",
    "        #X_train, X_test, y_train, y_test=self.split_normolize_data(data)\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "        self.X_test=X_test\n",
    "        self.y_test=y_test\n",
    "\n",
    "    ##############################\n",
    "\n",
    "\n",
    "    # >> MODEL TRAINING << #\n",
    "    def compute_cost(self,W, X, Y):\n",
    "        # calculate hinge loss\n",
    "        N = X.shape[0]\n",
    "        distances = 1 - Y * (np.dot(X, W))\n",
    "        distances[distances < 0] = 0 \n",
    "        hinge_loss = self.regularization_strength * (np.sum(distances) / N)\n",
    "\n",
    "        # calculate cost\n",
    "        cost = 1 / 2 * np.dot(W, W) + hinge_loss\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def calculate_cost_gradient(self,W, X_batch, Y_batch):\n",
    "       \n",
    "        if type(Y_batch) == np.float64:\n",
    "            Y_batch = np.array([Y_batch])\n",
    "            X_batch = np.array([X_batch])  \n",
    "\n",
    "        distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "        dw = np.zeros(len(W))\n",
    "\n",
    "        for ind, d in enumerate(distance):\n",
    "            if max(0, d) == 0:\n",
    "                di = W\n",
    "            else:\n",
    "                di = W - (self.regularization_strength * Y_batch[ind] * X_batch[ind])\n",
    "            dw += di\n",
    "\n",
    "        dw = dw/len(Y_batch)  # average\n",
    "        return dw\n",
    "\n",
    "\n",
    "    def sgd(self):\n",
    "        #features=self.X_train.to_numpy()\n",
    "        features=self.X_train\n",
    "        #outputs=self.y_train\n",
    "        outputs=self.y_train.to_numpy()\n",
    "        max_epochs = 5000\n",
    "        weights = np.zeros(features.shape[1])\n",
    "        nth = 0\n",
    "        prev_cost = float(\"inf\")\n",
    "        cost_threshold = 0.01  # in percent\n",
    "        # stochastic gradient descent\n",
    "        for epoch in range(1, max_epochs):\n",
    "            X, Y = shuffle(features, outputs)\n",
    "            for ind, x in enumerate(X):\n",
    "               # print(Y[ind])\n",
    "                ascent = self.calculate_cost_gradient(weights, x, Y[ind])\n",
    "                weights = weights - (self.learning_rate * ascent)\n",
    "\n",
    "            # convergence check on 2^nth epoch\n",
    "            if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "                cost = self.compute_cost(weights, features, outputs)\n",
    "                print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
    "                # stoppage criterion\n",
    "                if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                    return weights\n",
    "                prev_cost = cost\n",
    "                nth += 1\n",
    "        return weights\n",
    "\n",
    "\n",
    "    ########################\n",
    "\n",
    "\n",
    "    def init(self):\n",
    "        print(\"training started...\")\n",
    "        W = self.sgd()\n",
    "        print(\"training finished.\")\n",
    "        print(\"weights are: {}\".format(W))\n",
    "\n",
    "        # testing the model\n",
    "        print(\"testing the model...\")\n",
    "        y_train_predicted = np.array([])\n",
    "        for i in range(self.X_train.shape[0]):\n",
    "            yp = np.sign(np.dot(self.X_train[i], W))\n",
    "            y_train_predicted = np.append(y_train_predicted, yp)\n",
    "\n",
    "        y_test_predicted = np.array([])\n",
    "        for i in range(self.X_test.shape[0]):\n",
    "            yp = np.sign(np.dot(self.X_test[i], W))\n",
    "            y_test_predicted = np.append(y_test_predicted, yp)\n",
    "        return self.y_test,y_test_predicted\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # set hyper-parameters and call init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying feature engineering...\n",
      "splitting dataset into train and test sets...\n",
      "kernel= PolynomialCountSketch()\n",
      "training started...\n",
      "Epoch is: 1 and Cost is: 6117.00472651649\n",
      "Epoch is: 2 and Cost is: 4686.255137898888\n",
      "Epoch is: 4 and Cost is: 3404.85507601705\n",
      "Epoch is: 8 and Cost is: 2543.9814780456977\n",
      "Epoch is: 16 and Cost is: 1919.0505549096847\n",
      "Epoch is: 32 and Cost is: 1583.1062440642409\n",
      "Epoch is: 64 and Cost is: 1309.3672873850132\n",
      "Epoch is: 128 and Cost is: 1143.837960353479\n",
      "Epoch is: 256 and Cost is: 999.2443949232363\n",
      "Epoch is: 512 and Cost is: 920.0717172370312\n",
      "Epoch is: 1024 and Cost is: 883.8024162762517\n",
      "Epoch is: 2048 and Cost is: 861.5759992709595\n",
      "Epoch is: 4096 and Cost is: 854.496211499569\n",
      "training finished.\n",
      "weights are: [-2.77423921e+00 -6.29527933e-01 -5.56911758e-01  2.32233046e+00\n",
      "  4.70077438e+00 -2.08618833e+00  1.24718036e+00  3.31316441e+00\n",
      " -2.33637016e-15  7.55679809e-01 -1.21364301e-01 -1.03937273e+00\n",
      " -3.59151431e-01 -8.72675584e-15 -7.38572695e-01 -1.39890166e-16\n",
      " -4.29906790e+00 -2.29822091e-01  1.59932286e+00 -7.38764291e-01\n",
      " -6.06016103e+00  1.29789078e+00 -4.27621989e-15  3.98196498e-15\n",
      "  2.95137417e-15 -1.25249584e+00  1.90459933e+00  2.27364494e+00\n",
      "  2.32957074e-01  7.05013156e-01 -4.07030314e+00  8.96198148e-01\n",
      "  3.90052645e-16  2.98997514e+00  3.68762392e-15  6.25426008e+00\n",
      " -2.79906377e+00 -7.37230801e-01  6.07000361e-01 -1.04956817e+00\n",
      " -4.60003458e-15  2.01673424e+00 -6.16322547e-02 -2.27364494e+00\n",
      " -4.95434514e+00 -3.33163531e+00  3.08498732e+00 -6.05394515e-16\n",
      "  7.37230801e-01 -3.10948070e-16 -4.13948224e-01 -1.45290874e+00\n",
      " -9.93977722e-01 -1.83165180e+00 -1.10055061e+00 -8.50242351e-15\n",
      "  2.67629568e+00 -3.20887223e-16  1.46146285e-15 -8.31303478e-02\n",
      " -3.03243688e+00 -3.81610529e+00 -1.49539479e-16  3.47083033e-15\n",
      " -6.99709145e-15 -6.82829812e-02  1.29666640e+00 -2.05184275e+00\n",
      " -4.18691377e-01  2.39109472e+00 -7.04579015e-01  2.76046505e+00\n",
      "  3.15235609e+00  7.20132178e-16  5.97022881e-01 -1.42613231e+00\n",
      "  2.72486058e+00  3.84790539e-15 -2.07309063e+00  3.86967557e+00\n",
      "  8.03984418e-15 -2.85957811e+00 -9.50809827e-15 -4.09054747e-01\n",
      "  1.24718036e+00 -1.72560171e+00  3.97339324e-01 -3.97600974e-15\n",
      " -6.34170591e-16 -4.07751159e-02  8.79550803e-16 -5.94360372e-01\n",
      "  2.15312709e+00  2.35889385e-01 -3.93152338e+00 -1.12100419e+00\n",
      "  2.66852427e+00 -5.71661025e-15  2.76173007e+00 -5.46007320e-15]\n",
      "testing the model...\n",
      "accuracy on test dataset: 0.9736842105263158\n",
      "recall on test dataset: 0.9361702127659575\n",
      "precision on test dataset: 0.9361702127659575\n",
      "applying feature engineering...\n",
      "splitting dataset into train and test sets...\n",
      "kernel= AdditiveChi2Sampler()\n",
      "training started...\n",
      "Epoch is: 1 and Cost is: 7080.557452558283\n",
      "Epoch is: 2 and Cost is: 6217.371335725616\n",
      "Epoch is: 4 and Cost is: 5219.01919895025\n",
      "Epoch is: 8 and Cost is: 3138.9798167476674\n",
      "Epoch is: 16 and Cost is: 2229.919052256699\n",
      "Epoch is: 32 and Cost is: 1602.729645747898\n",
      "Epoch is: 64 and Cost is: 1252.8796193012267\n",
      "Epoch is: 128 and Cost is: 1078.9418403127374\n",
      "Epoch is: 256 and Cost is: 952.0197595769456\n",
      "Epoch is: 512 and Cost is: 879.2075666937421\n",
      "Epoch is: 1024 and Cost is: 847.7452400105961\n",
      "Epoch is: 2048 and Cost is: 839.1244694002809\n",
      "Epoch is: 4096 and Cost is: 831.2301451247698\n",
      "training finished.\n",
      "weights are: [ 2.26656704  5.61388799  0.33306573 -5.10484527  4.44649115 -1.73926567\n",
      " -3.6481351  -0.21605196 -3.91895678  0.45104998  0.30830778  4.0001586\n",
      " -2.8887275   4.30419282  8.44174508  1.43371726 -4.94390084  6.06346738\n",
      " -1.07851818 -3.2220227   0.82879156 -3.13516587  0.90634769  1.58216258\n",
      "  5.82778321 -2.57902645 -1.21535476  1.13736522 -0.38174132  1.65073526\n",
      " -0.80992     3.77913293 -1.95197989  0.96959648  2.8272883   2.994473\n",
      "  2.0791154  -0.51271211  0.        ]\n",
      "testing the model...\n",
      "accuracy on test dataset: 0.9824561403508771\n",
      "recall on test dataset: 0.9574468085106383\n",
      "precision on test dataset: 0.9574468085106383\n",
      "applying feature engineering...\n",
      "splitting dataset into train and test sets...\n",
      "kernel= RBFSampler()\n",
      "training started...\n",
      "Epoch is: 1 and Cost is: 6190.63690119355\n",
      "Epoch is: 2 and Cost is: 5654.844531810931\n",
      "Epoch is: 4 and Cost is: 4610.370940630497\n",
      "Epoch is: 8 and Cost is: 3442.728015174002\n",
      "Epoch is: 16 and Cost is: 2641.434764946075\n",
      "Epoch is: 32 and Cost is: 2035.6952398968103\n",
      "Epoch is: 64 and Cost is: 1577.4021650555933\n",
      "Epoch is: 128 and Cost is: 1330.8388523858305\n",
      "Epoch is: 256 and Cost is: 1173.271363758909\n",
      "Epoch is: 512 and Cost is: 1064.768724265964\n",
      "Epoch is: 1024 and Cost is: 997.458422195896\n",
      "Epoch is: 2048 and Cost is: 970.2612992492793\n",
      "Epoch is: 4096 and Cost is: 962.9532160784145\n",
      "training finished.\n",
      "weights are: [-2.53590634  1.01284265  3.85120575 -1.31750754  1.5519996  -0.79984265\n",
      "  0.94484454 -2.44648833  2.05204907 -0.58046649 -2.39726562 -0.69470445\n",
      " -5.39105285  2.0648834   2.27466806 -0.42602405  2.95560331 -1.96526345\n",
      " -2.30992861  2.14244612 -0.18511354  0.97781369 -2.1450616   0.10401211\n",
      "  3.32687301  0.10558737  1.05984771 -1.56863642  0.80495004 -2.38630217\n",
      "  1.675215   -0.61753136 -1.36369608 -0.03179661  0.35685373 -0.33444498\n",
      "  1.29908022 -1.35736832 -1.04045919 -2.77633125 -3.1768864   2.52823688\n",
      " -0.15738327 -0.60830907  1.48759544 -1.16610272  0.66515429  0.22520724\n",
      " -1.36899734  4.58772376 -1.25077852  1.12753791  2.81916969 -3.35534097\n",
      "  1.26235425 -2.85074939 -0.97580266  2.82272545 -1.34705839  1.92371651\n",
      "  2.55438454  0.50721173 -3.95927035 -1.85363667 -0.90486067  1.37253955\n",
      "  1.34881466  5.12660099  0.1834493   0.43436551  2.12162634 -0.83677215\n",
      "  3.00434963  4.35648041  0.5100037   5.16706282 -1.54344958 -1.21968663\n",
      " -3.2209613  -1.10736261 -0.43012067 -1.516882   -2.03550958  1.0730379\n",
      " -1.07868884 -1.7792708   8.80687226 -3.16052573  2.8078515  -0.30131174\n",
      " -0.34533439 -0.71918475 -2.18455893 -1.53654075 -4.94038666  3.94187707\n",
      " -0.79797862  0.38022041  1.58149252  0.86235495]\n",
      "testing the model...\n",
      "accuracy on test dataset: 0.9736842105263158\n",
      "recall on test dataset: 0.9574468085106383\n",
      "precision on test dataset: 0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "#X,Y=data_normolize(data)\n",
    "kernels=[PolynomialCountSketch(),AdditiveChi2Sampler(),RBFSampler()]\n",
    "for kernel in kernels:\n",
    "    X_train, X_test, y_train, y_test=split_normolize_data(kernel)\n",
    "    svc=SVC_hand(kernel=kernel)\n",
    "    #ps = PolynomialCountSketch(degree=3, random_state=1)\n",
    "    svc.fit(X_train, X_test, y_train, y_test)\n",
    "    y_test,y_test_predicted=svc.init()\n",
    "    print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "    print(\"recall on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "    print(\"precision on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying feature engineering...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.drop(data.columns[[-1, 0]], axis=1, inplace=True)\n",
    "print(\"applying feature engineering...\")\n",
    "diag_map = {'M': 1.0, 'B': -1.0}\n",
    "data['diagnosis'] = data['diagnosis'].map(diag_map)\n",
    "Y = data['diagnosis']\n",
    "X = data.iloc[:,1 :]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "def test_different_kernel():\n",
    "    kernels=['rbf','linear','sigmoid']\n",
    "    y_pred=[]\n",
    "    for kernel in kernels:\n",
    "        print(1)\n",
    "        model=SVC(kernel=kernel,degree=2,gamma=20)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred.append(model.predict(X_test))\n",
    "        #print(\"Точность модели c kernel {}: {}\".format(kernel,accuracy_score(y_test, y_pred)))\n",
    "    return y_pred,kernels     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "Точность модели c kernel {'rbf'}: 0.5877192982456141\n",
      "Точность модели c kernel {'linear'}: 0.956140350877193\n",
      "Точность модели c kernel {'sigmoid'}: 0.5877192982456141\n",
      "precomputed kernel работает только с квадратными матрицами\n",
      "poly kernel при степени=2 дает точность 0.8535(по умолчанию степень равна 3) \n",
      "при gamma=20 rbf дает точность= 0.878787878, poly дает точность=0.92424(по умолчанию gamma= scale) \n"
     ]
    }
   ],
   "source": [
    "pred,kernels=test_different_kernel()\n",
    "for i in range(len(pred)):\n",
    "    print(\"Точность модели c kernel {}: {}\".format({kernels[i]},accuracy_score(y_test, pred[i])))\n",
    "print(\"precomputed kernel работает только с квадратными матрицами\")\n",
    "print(\"poly kernel при степени=2 дает точность 0.8535(по умолчанию степень равна 3) \")\n",
    "print(\"при gamma=20 rbf дает точность= 0.878787878, poly дает точность=0.92424(по умолчанию gamma= scale) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
